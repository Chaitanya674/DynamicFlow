{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd919f2",
   "metadata": {},
   "source": [
    "## Dynamic Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ae1e1",
   "metadata": {},
   "source": [
    "### Phase-I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66739c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9306b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "import operator\n",
    "\n",
    "class Task(TypedDict):\n",
    "    id: str\n",
    "    description: str\n",
    "    assigned_agent: str \n",
    "    status: str\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    requirements: str\n",
    "    project_root: str\n",
    "\n",
    "    architecture: Optional[str]\n",
    "    execution_plan: Optional[str]\n",
    "    task_queue: List[Task]\n",
    "\n",
    "    current_task: Optional[Task]\n",
    "    recent_code_changes: List[str]\n",
    "\n",
    "    test_logs: Optional[str]\n",
    "    error_analysis: Optional[str]\n",
    "\n",
    "    iteration_count: int  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0aeba",
   "metadata": {},
   "source": [
    "### Creating Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c3a1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_file(file_path: str, content: str):\n",
    "    \"\"\"\n",
    "    Writes content to a file. \n",
    "    Args:\n",
    "        file_path: strict path under ./builds/app-x/\n",
    "        content: the full code or text to write\n",
    "    \"\"\"\n",
    "\n",
    "    if \"builds/\" not in file_path:\n",
    "        return \"Error: You can only write inside the 'builds/' directory.\"\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(content)\n",
    "        return f\"Successfully wrote {len(content)} bytes to {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing file: {e}\"\n",
    "\n",
    "@tool\n",
    "def read_file(file_path: str):\n",
    "    \"\"\"Reads a file. Args: file_path\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def run_shell_command(command: str, work_dir: str):\n",
    "    \"\"\"\n",
    "    Executes a terminal command.\n",
    "    Args:\n",
    "        command: e.g., 'python main.py' or 'npm install'\n",
    "        work_dir: the directory to run in (e.g., ./builds/app-1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            command,\n",
    "            cwd=work_dir,\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=20\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return f\"SUCCESS:\\n{result.stdout}\"\n",
    "        else:\n",
    "            return f\"FAILED:\\nSTDOUT: {result.stdout}\\nSTDERR: {result.stderr}\"\n",
    "    except Exception as e:\n",
    "        return f\"System Error: {e}\"\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:8b\", \n",
    "    temperature=0,\n",
    "    format=\"json\" \n",
    ")\n",
    "\n",
    "llm_worker = llm.bind_tools([write_file, read_file, run_shell_command])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aaa178",
   "metadata": {},
   "source": [
    "### Creating Agent Phase-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e3daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from prompts import *\n",
    "import operator\n",
    "\n",
    "def architect_node(state: AgentState):\n",
    "    print(f\"\\nðŸ—ï¸  Architecting {state['project_root']}...\")\n",
    "    msg = architect_prompt.format(\n",
    "        project_root=state[\"project_root\"],\n",
    "        requirements=state[\"requirements\"]\n",
    "    )\n",
    "    response = llm.invoke(msg)\n",
    "    return {\"architecture\": response.content}\n",
    "\n",
    "\n",
    "def orchestrator_node(state: AgentState):\n",
    "    print(\"\\nðŸŽ¼ Orchestrating...\")\n",
    "    msg = orchestrator_prompt.format(\n",
    "        architecture=state[\"architecture\"]\n",
    "    )\n",
    "    response = llm.invoke(msg)\n",
    "    return {\"execution_plan\": response.content}\n",
    "\n",
    "\n",
    "def planner_node(state: AgentState):\n",
    "    print(\"\\nðŸ“… Planning Tasks...\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. DO NOT REPLAN IF TASKS ALREADY EXIST\n",
    "    # --------------------------------------------------\n",
    "    if state.get(\"task_queue\"):\n",
    "        print(\"â­ï¸  Planner skipped: existing tasks in queue\")\n",
    "        return {}\n",
    "\n",
    "    errs = state.get(\"error_analysis\")\n",
    "\n",
    "    msg = planner_prompt.format(\n",
    "        execution_plan=state.get(\"execution_plan\"),\n",
    "        error_analysis=errs,\n",
    "        project_root=state[\"project_root\"]\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(msg)\n",
    "\n",
    "    try:\n",
    "        content = response.content\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 2. STRIP MARKDOWN FENCES\n",
    "        # --------------------------------------------------\n",
    "        if \"```json\" in content:\n",
    "            content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "        elif \"```\" in content:\n",
    "            content = content.split(\"```\")[1].split(\"```\")[0]\n",
    "\n",
    "        parsed = json.loads(content)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 3. UNWRAP COMMON SHAPES\n",
    "        # --------------------------------------------------\n",
    "        if isinstance(parsed, dict) and \"tasks\" in parsed:\n",
    "            parsed = parsed[\"tasks\"]\n",
    "\n",
    "        if isinstance(parsed, dict):\n",
    "            parsed = [parsed]\n",
    "\n",
    "        if not isinstance(parsed, list):\n",
    "            raise ValueError(\"Planner output must be a list of tasks\")\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 4. NORMALIZE + ENFORCE TASK SCHEMA\n",
    "        # --------------------------------------------------\n",
    "        new_tasks = []\n",
    "\n",
    "        for task in parsed:\n",
    "            if not isinstance(task, dict):\n",
    "                raise ValueError(f\"Invalid task type: {type(task)}\")\n",
    "\n",
    "            description = task.get(\"description\")\n",
    "            if not description:\n",
    "                raise ValueError(f\"Task missing description: {task}\")\n",
    "\n",
    "            assigned_agent = task.get(\"assigned_agent\", \"backend\")\n",
    "\n",
    "            # Planner NEVER executes tasks\n",
    "            if assigned_agent == \"planner\":\n",
    "                assigned_agent = \"backend\"\n",
    "\n",
    "            normalized_task = {\n",
    "                \"id\": task.get(\"id\", f\"task_{len(new_tasks) + 1}\"),\n",
    "                \"description\": description,\n",
    "                \"assigned_agent\": assigned_agent,\n",
    "                \"status\": task.get(\"status\", \"pending\"),\n",
    "            }\n",
    "\n",
    "            new_tasks.append(normalized_task)\n",
    "\n",
    "        print(f\"âœ… Generated {len(new_tasks)} tasks\")\n",
    "\n",
    "        return {\n",
    "            \"task_queue\": new_tasks,\n",
    "            \"error_analysis\": None,\n",
    "            \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Planner JSON Error: {e}\")\n",
    "        return {\n",
    "            \"task_queue\": [],\n",
    "            \"error_analysis\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def worker_node(state: AgentState):\n",
    "    if not state[\"task_queue\"]:\n",
    "        return {}\n",
    "\n",
    "    current_task = state[\"task_queue\"][0]\n",
    "    remaining_tasks = state[\"task_queue\"][1:]\n",
    "\n",
    "    # ---- DEFENSIVE CHECK (saves your sanity) ----\n",
    "    if not isinstance(current_task, dict):\n",
    "        raise TypeError(\n",
    "            f\"Invalid task format. Expected dict, got {type(current_task)}: {current_task}\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"\\nðŸ‘· {current_task['assigned_agent'].upper()} Working on: \"\n",
    "        f\"{current_task['description']}\"\n",
    "    )\n",
    "\n",
    "    msg = backend_prompt_template.format(\n",
    "        task_description=current_task[\"description\"],\n",
    "        project_root=state[\"project_root\"]\n",
    "    )\n",
    "\n",
    "    llm_worker.invoke(msg)\n",
    "\n",
    "    return {\n",
    "        \"current_task\": current_task,\n",
    "        \"task_queue\": remaining_tasks,\n",
    "        \"recent_code_changes\": [\n",
    "            f\"Executed task: {current_task['description']}\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def tester_node(state: AgentState):\n",
    "    print(\"\\nðŸ§ª Testing...\")\n",
    "    msg = tester_prompt_template.format(\n",
    "        project_root=state[\"project_root\"]\n",
    "    )\n",
    "    response = llm_worker.invoke(msg)\n",
    "    return {\"test_logs\": response.content}\n",
    "\n",
    "\n",
    "def reviewer_node(state: AgentState):\n",
    "    print(\"\\nðŸ§ Reviewing Results...\")\n",
    "    logs = state.get(\"test_logs\") or \"\"\n",
    "\n",
    "    if \"SUCCESS\" in logs and \"Error\" not in logs:\n",
    "        return {\"error_analysis\": None}\n",
    "\n",
    "    msg = reviewer_prompt.format(test_logs=logs)\n",
    "    response = llm.invoke(msg)\n",
    "    return {\"error_analysis\": response.content}\n",
    "\n",
    "\n",
    "def check_queue(state: AgentState):\n",
    "    if state[\"task_queue\"]:\n",
    "        return \"work\"\n",
    "    return \"test\"\n",
    "\n",
    "\n",
    "def check_review(state: AgentState):\n",
    "    if state.get(\"error_analysis\") is None:\n",
    "        return \"end\"\n",
    "    if state.get(\"iteration_count\", 0) >= 5:\n",
    "        print(\"âŒ Max retries reached.\")\n",
    "        return \"end\"\n",
    "    return \"fix\"\n",
    "\n",
    "\n",
    "workflow = StateGraph(\n",
    "    AgentState,\n",
    "    reducers={\n",
    "        \"task_queue\": operator.add,\n",
    "        \"recent_code_changes\": operator.add,\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_node(\"architect\", architect_node)\n",
    "workflow.add_node(\"orchestrator\", orchestrator_node)\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"worker\", worker_node)\n",
    "workflow.add_node(\"tester\", tester_node)\n",
    "workflow.add_node(\"reviewer\", reviewer_node)\n",
    "\n",
    "workflow.set_entry_point(\"architect\")\n",
    "workflow.add_edge(\"architect\", \"orchestrator\")\n",
    "workflow.add_edge(\"orchestrator\", \"planner\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"planner\",\n",
    "    check_queue,\n",
    "    {\"work\": \"worker\", \"test\": \"tester\"}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"worker\", \"planner\")\n",
    "workflow.add_edge(\"tester\", \"reviewer\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"reviewer\",\n",
    "    check_review,\n",
    "    {\"fix\": \"planner\", \"end\": END}\n",
    ")\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d35a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ—ï¸  Architecting ./builds/app-calculator...\n",
      "Finished: architect\n",
      "\n",
      "ðŸŽ¼ Orchestrating...\n",
      "Finished: orchestrator\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "âœ… Generated 3 tasks\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Install required dependencies and set up the project structure\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "â­ï¸  Planner skipped: existing tasks in queue\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Write Python code for the calculator application in `calculator.py` file\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "â­ï¸  Planner skipped: existing tasks in queue\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Modify the `history.txt` file to log user's input and output in JSON format\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "âœ… Generated 3 tasks\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Install required dependencies and set up the project structure\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "â­ï¸  Planner skipped: existing tasks in queue\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Write Python code for the calculator application in `calculator.py` file\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "â­ï¸  Planner skipped: existing tasks in queue\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Modify the `history.txt` file to log user's input and output in JSON format\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "âœ… Generated 3 tasks\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Install required dependencies and set up the project structure\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "â­ï¸  Planner skipped: existing tasks in queue\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Write Python code for the calculator application in `calculator.py` file\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "â­ï¸  Planner skipped: existing tasks in queue\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Modify the `history.txt` file to log user's input and output in JSON format\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "âœ… Generated 3 tasks\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Install required dependencies and set up the project structure\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "â­ï¸  Planner skipped: existing tasks in queue\n",
      "Finished: planner\n",
      "\n",
      "ðŸ‘· BACKEND Working on: Write Python code for the calculator application in `calculator.py` file\n",
      "Finished: worker\n",
      "\n",
      "ðŸ“… Planning Tasks...\n",
      "â­ï¸  Planner skipped: existing tasks in queue\n",
      "Finished: planner\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langgraph/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      1\u001b[39m inputs = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrequirements\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCreate a simple Python calculator CLI that logs history to a text file.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproject_root\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m./builds/app-calculator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33miteration_count\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m\n\u001b[32m     16\u001b[39m }\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# This prints the state updates as they happen\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFinished: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/AI/5-day-agentic-ai/DynamicFlow/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2671\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2663\u001b[39m     msg = create_error_message(\n\u001b[32m   2664\u001b[39m         message=(\n\u001b[32m   2665\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2669\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2670\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2671\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2672\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2673\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://docs.langchain.com/oss/python/langgraph/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"requirements\": \"Create a simple Python calculator CLI that logs history to a text file.\",\n",
    "    \"project_root\": \"./builds/app-calculator\",\n",
    "\n",
    "    \"architecture\": None,\n",
    "    \"execution_plan\": None,\n",
    "    \"task_queue\": [],\n",
    "\n",
    "    \"current_task\": None,\n",
    "    \"recent_code_changes\": [],\n",
    "\n",
    "    \"test_logs\": None,\n",
    "    \"error_analysis\": None,\n",
    "\n",
    "    \"iteration_count\": 0\n",
    "}\n",
    "\n",
    "\n",
    "# Run\n",
    "for output in app.stream(inputs):\n",
    "    # This prints the state updates as they happen\n",
    "    for key, value in output.items():\n",
    "        print(f\"Finished: {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d3c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
